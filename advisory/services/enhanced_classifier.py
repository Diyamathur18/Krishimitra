#!/usr/bin/env python3
"""
Enhanced Query Classification System
Improves accuracy for general and mixed query recognition
"""

import re
import logging
from typing import Dict, List, Any, Tuple
from datetime import datetime

logger = logging.getLogger(__name__)

class EnhancedQueryClassifier:
    """Enhanced query classification with improved accuracy"""
    
    def __init__(self):
        # Enhanced keyword patterns
        self.farming_patterns = {
            'crops': [
                'crop', 'à¤«à¤¸à¤²', 'crops', 'cultivation', 'à¤–à¥‡à¤¤à¥€', 'farming', 'agriculture', 'à¤•à¥ƒà¤·à¤¿',
                'wheat', 'à¤—à¥‡à¤¹à¥‚à¤‚', 'rice', 'à¤šà¤¾à¤µà¤²', 'maize', 'à¤®à¤•à¥à¤•à¤¾', 'cotton', 'à¤•à¤ªà¤¾à¤¸',
                'sugarcane', 'à¤—à¤¨à¥à¤¨à¤¾', 'potato', 'à¤†à¤²à¥‚', 'tomato', 'à¤Ÿà¤®à¤¾à¤Ÿà¤°', 'onion', 'à¤ªà¥à¤¯à¤¾à¤œ',
                'vegetable', 'à¤¸à¤¬à¥à¤œà¥€', 'fruits', 'à¤«à¤²', 'pulses', 'à¤¦à¤¾à¤²', 'oilseeds', 'à¤¤à¤¿à¤²à¤¹à¤¨',
                'lagayein', 'à¤²à¤—à¤¾à¤à¤‚', 'lagana', 'à¤²à¤—à¤¾à¤¨à¤¾', 'suggest', 'à¤¸à¥à¤à¤¾à¤µ', 'recommend', 'à¤…à¤¨à¥à¤¶à¤‚à¤¸à¤¾',
                'kya', 'à¤•à¥à¤¯à¤¾', 'kaun si', 'à¤•à¥Œà¤¨ à¤¸à¥€', 'which', 'best', 'à¤¬à¥‡à¤¸à¥à¤Ÿ', 'suitable', 'à¤‰à¤ªà¤¯à¥à¤•à¥à¤¤',
                'mein', 'à¤®à¥‡à¤‚', 'in', 'for', 'à¤•à¥‡ à¤²à¤¿à¤', 'grow', 'à¤‰à¤—à¤¾à¤¨à¤¾', 'plant', 'à¤ªà¥Œà¤§à¤¾'
            ],
            'market': [
                'price', 'à¤•à¥€à¤®à¤¤', 'rate', 'à¤¦à¤°', 'market', 'à¤¬à¤¾à¤œà¤¾à¤°', 'mandi', 'à¤®à¤‚à¤¡à¥€',
                'selling', 'à¤¬à¥‡à¤šà¤¨à¤¾', 'buying', 'à¤–à¤°à¥€à¤¦à¤¨à¤¾', 'profit', 'à¤²à¤¾à¤­', 'loss', 'à¤¨à¥à¤•à¤¸à¤¾à¤¨',
                'msp', 'minimum support price', 'procurement', 'à¤–à¤°à¥€à¤¦', 'trading', 'à¤µà¥à¤¯à¤¾à¤ªà¤¾à¤°',
                'à¤­à¤¾à¤µ', 'bazaar', 'cotton', 'à¤•à¤ªà¤¾à¤¸', 'cotton market', 'cotton price',
                'cotton ka', 'à¤•à¤ªà¤¾à¤¸ à¤•à¤¾', 'cotton à¤•à¤¾', 'msp', 'à¤à¤®à¤à¤¸à¤ªà¥€', 'minimum support'
            ],
            'weather': [
                'weather', 'à¤®à¥Œà¤¸à¤®', 'rain', 'à¤¬à¤¾à¤°à¤¿à¤¶', 'rainfall', 'à¤µà¤°à¥à¤·à¤¾', 'temperature', 'à¤¤à¤¾à¤ªà¤®à¤¾à¤¨',
                'humidity', 'à¤¨à¤®à¥€', 'wind', 'à¤¹à¤µà¤¾', 'forecast', 'à¤ªà¥‚à¤°à¥à¤µà¤¾à¤¨à¥à¤®à¤¾à¤¨', 'climate', 'à¤œà¤²à¤µà¤¾à¤¯à¥',
                'drought', 'à¤¸à¥‚à¤–à¤¾', 'flood', 'à¤¬à¤¾à¤¢à¤¼', 'storm', 'à¤¤à¥‚à¤«à¤¾à¤¨', 'season', 'à¤®à¥Œà¤¸à¤®',
                'à¤¬à¤¾à¤°à¤¿à¤¶ à¤•à¤¾', 'rain forecast', 'temperature in', 'à¤®à¥à¤‚à¤¬à¤ˆ', 'mumbai', 'à¤¬à¥‡à¤‚à¤—à¤²à¥à¤°à¥',
                'bangalore', 'delhi', 'à¤¦à¤¿à¤²à¥à¤²à¥€', 'weather in', 'à¤®à¥Œà¤¸à¤® à¤®à¥‡à¤‚', 'today', 'à¤†à¤œ'
            ],
            'pest_disease': [
                'pest', 'à¤•à¥€à¤Ÿ', 'disease', 'à¤°à¥‹à¤—', 'insect', 'à¤•à¥€à¤¡à¤¼à¤¾', 'fungus', 'à¤«à¤«à¥‚à¤‚à¤¦',
                'control', 'à¤¨à¤¿à¤¯à¤‚à¤¤à¥à¤°à¤£', 'treatment', 'à¤‰à¤ªà¤šà¤¾à¤°', 'medicine', 'à¤¦à¤µà¤¾', 'spray', 'à¤›à¤¿à¤¡à¤¼à¤•à¤¾à¤µ',
                'infection', 'à¤¸à¤‚à¤•à¥à¤°à¤®à¤£', 'damage', 'à¤¨à¥à¤•à¤¸à¤¾à¤¨', 'healthy', 'à¤¸à¥à¤µà¤¸à¥à¤¥', 'sick', 'à¤¬à¥€à¤®à¤¾à¤°'
            ],
            'fertilizer': [
                'fertilizer', 'à¤‰à¤°à¥à¤µà¤°à¤•', 'manure', 'à¤–à¤¾à¤¦', 'compost', 'à¤•à¤‚à¤ªà¥‹à¤¸à¥à¤Ÿ', 'nutrient', 'à¤ªà¥‹à¤·à¤•',
                'npk', 'nitrogen', 'à¤«à¥‰à¤¸à¥à¤«à¥‹à¤°à¤¸', 'potassium', 'à¤ªà¥‹à¤Ÿà¤¾à¤¶', 'organic', 'à¤œà¥ˆà¤µà¤¿à¤•',
                'chemical', 'à¤°à¤¾à¤¸à¤¾à¤¯à¤¨à¤¿à¤•', 'dose', 'à¤®à¤¾à¤¤à¥à¤°à¤¾', 'application', 'à¤ªà¥à¤°à¤¯à¥‹à¤—'
            ],
            'government': [
                'scheme', 'à¤¯à¥‹à¤œà¤¨à¤¾', 'subsidy', 'à¤¸à¤¬à¥à¤¸à¤¿à¤¡à¥€', 'government', 'à¤¸à¤°à¤•à¤¾à¤°', 'pm kisan',
                'pmfby', 'soil health card', 'kisan credit card', 'pmksy', 'loan', 'à¤•à¤°à¥à¤œ',
                'benefit', 'à¤²à¤¾à¤­', 'support', 'à¤¸à¤¹à¤¾à¤¯à¤¤à¤¾', 'assistance', 'à¤®à¤¦à¤¦', 'help', 'à¤¸à¤¹à¤¾à¤¯à¤¤à¤¾',
                'à¤•à¥ƒà¤·à¤¿ à¤¸à¤¬à¥à¤¸à¤¿à¤¡à¥€', 'agriculture subsidy', 'à¤¸à¤¬à¥à¤¸à¤¿à¤¡à¥€ à¤•à¥€ à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€', 'subsidy information',
                'à¤¸à¤°à¤•à¤¾à¤°à¥€ à¤®à¤¦à¤¦', 'government help', 'à¤®à¤¦à¤¦ à¤•à¥ˆà¤¸à¥‡', 'help how', 'à¤¸à¤¹à¤¾à¤¯à¤¤à¤¾ à¤•à¥ˆà¤¸à¥‡'
            ],
            'irrigation': [
                'irrigation', 'à¤¸à¤¿à¤‚à¤šà¤¾à¤ˆ', 'water', 'à¤ªà¤¾à¤¨à¥€', 'watering', 'à¤¸à¤¿à¤‚à¤šà¤¾à¤ˆ à¤•à¤°à¤¨à¤¾', 'drip', 'à¤¡à¥à¤°à¤¿à¤ª',
                'sprinkler', 'à¤¸à¥à¤ªà¥à¤°à¤¿à¤‚à¤•à¤²à¤°', 'pump', 'à¤ªà¤‚à¤ª', 'well', 'à¤•à¥à¤†à¤‚', 'canal', 'à¤¨à¤¹à¤°',
                'drainage', 'à¤œà¤² à¤¨à¤¿à¤•à¤¾à¤¸à¥€', 'moisture', 'à¤¨à¤®à¥€', 'dry', 'à¤¸à¥‚à¤–à¤¾', 'wet', 'à¤—à¥€à¤²à¤¾'
            ],
            'soil': [
                'soil', 'à¤®à¤¿à¤Ÿà¥à¤Ÿà¥€', 'land', 'à¤œà¤®à¥€à¤¨', 'earth', 'à¤­à¥‚à¤®à¤¿', 'fertile', 'à¤‰à¤ªà¤œà¤¾à¤Š',
                'sandy', 'à¤°à¥‡à¤¤à¤²à¥€', 'clayey', 'à¤šà¤¿à¤•à¤¨à¥€', 'loamy', 'à¤¦à¥‹à¤®à¤Ÿ', 'ph', 'à¤ªà¥€à¤à¤š',
                'testing', 'à¤œà¤¾à¤‚à¤š', 'health', 'à¤¸à¥à¤µà¤¾à¤¸à¥à¤¥à¥à¤¯', 'nutrient', 'à¤ªà¥‹à¤·à¤• à¤¤à¤¤à¥à¤µ',
                'à¤¦à¥‹à¤®à¤Ÿ à¤®à¤¿à¤Ÿà¥à¤Ÿà¥€', 'loamy soil', 'à¤®à¤¿à¤Ÿà¥à¤Ÿà¥€ à¤®à¥‡à¤‚', 'soil mein', 'à¤•à¥à¤¯à¤¾ à¤‰à¤—à¤¾à¤à¤‚', 'kya ugayein'
            ],
            'general_agriculture': [
                'agricultural', 'à¤•à¥ƒà¤·à¤¿', 'farming', 'à¤–à¥‡à¤¤à¥€', 'advice', 'à¤¸à¤²à¤¾à¤¹', 'counsel', 'à¤ªà¤°à¤¾à¤®à¤°à¥à¤¶',
                'agricultural advice', 'à¤•à¥ƒà¤·à¤¿ à¤¸à¤²à¤¾à¤¹', 'farming advice', 'à¤–à¥‡à¤¤à¥€ à¤¸à¤²à¤¾à¤¹', 'à¤•à¥ƒà¤·à¤¿ à¤ªà¤°à¤¾à¤®à¤°à¥à¤¶',
                'agricultural counsel', 'à¤®à¥à¤à¥‡ à¤•à¥ƒà¤·à¤¿', 'i need agricultural', 'à¤®à¥à¤à¥‡ farming', 'i need farming',
                'à¤¸à¤²à¤¾à¤¹ à¤šà¤¾à¤¹à¤¿à¤', 'advice chahiye', 'need advice', 'à¤šà¤¾à¤¹à¤¿à¤', 'chahiye', 'need',
                'real-time', 'à¤°à¤¿à¤¯à¤² à¤Ÿà¤¾à¤‡à¤®', 'market data', 'à¤®à¤¾à¤°à¥à¤•à¥‡à¤Ÿ à¤¡à¥‡à¤Ÿà¤¾', 'location', 'à¤²à¥‹à¤•à¥‡à¤¶à¤¨',
                'location based', 'à¤²à¥‹à¤•à¥‡à¤¶à¤¨ à¤•à¥‡ à¤…à¤¨à¥à¤¸à¤¾à¤°', 'data', 'à¤¡à¥‡à¤Ÿà¤¾', 'api', 'à¤à¤ªà¥€à¤†à¤ˆ'
            ]
        }
        
        self.general_patterns = {
            'greeting': [
                'hello', 'hi', 'hey', 'namaste', 'à¤¨à¤®à¤¸à¥à¤¤à¥‡', 'good morning', 'good afternoon',
                'good evening', 'how are you', 'à¤†à¤ª à¤•à¥ˆà¤¸à¥‡ à¤¹à¥ˆà¤‚', 'kaise ho', 'kaise hain'
            ],
            'trivia': [
                'trivia', 'quiz', 'question', 'à¤ªà¥à¤°à¤¶à¥à¤¨', 'fact', 'à¤¤à¤¥à¥à¤¯', 'knowledge', 'à¤œà¥à¤žà¤¾à¤¨',
                'random', 'à¤¯à¤¾à¤¦à¥ƒà¤šà¥à¤›à¤¿à¤•', 'general', 'à¤¸à¤¾à¤®à¤¾à¤¨à¥à¤¯', 'interesting', 'à¤°à¥‹à¤šà¤•'
            ],
            'numbers': [
                'number', 'à¤¸à¤‚à¤–à¥à¤¯à¤¾', 'digit', 'à¤…à¤‚à¤•', 'count', 'à¤—à¤¿à¤¨à¤¤à¥€', 'math', 'à¤—à¤£à¤¿à¤¤',
                'calculation', 'à¤—à¤£à¤¨à¤¾', 'statistics', 'à¤†à¤‚à¤•à¤¡à¤¼à¥‡', 'data', 'à¤¡à¥‡à¤Ÿà¤¾'
            ],
            'wikipedia': [
                'what is', 'à¤•à¥à¤¯à¤¾ à¤¹à¥ˆ', 'who is', 'à¤•à¥Œà¤¨ à¤¹à¥ˆ', 'when was', 'à¤•à¤¬ à¤¥à¤¾', 'where is', 'à¤•à¤¹à¤¾à¤‚ à¤¹à¥ˆ',
                'why', 'à¤•à¥à¤¯à¥‹à¤‚', 'how', 'à¤•à¥ˆà¤¸à¥‡', 'explain', 'à¤¸à¤®à¤à¤¾à¤à¤‚', 'tell me about', 'à¤¬à¤¤à¤¾à¤à¤‚'
            ],
            'activities': [
                'bored', 'à¤¬à¥‹à¤°', 'activity', 'à¤—à¤¤à¤¿à¤µà¤¿à¤§à¤¿', 'fun', 'à¤®à¤œà¤¾', 'entertainment', 'à¤®à¤¨à¥‹à¤°à¤‚à¤œà¤¨',
                'suggestion', 'à¤¸à¥à¤à¤¾à¤µ', 'idea', 'à¤µà¤¿à¤šà¤¾à¤°', 'hobby', 'à¤¶à¥Œà¤•', 'leisure', 'à¤…à¤µà¤•à¤¾à¤¶'
            ],
            'general_knowledge': [
                'capital', 'à¤°à¤¾à¤œà¤§à¤¾à¤¨à¥€', 'country', 'à¤¦à¥‡à¤¶', 'city', 'à¤¶à¤¹à¤°', 'history', 'à¤‡à¤¤à¤¿à¤¹à¤¾à¤¸',
                'science', 'à¤µà¤¿à¤œà¥à¤žà¤¾à¤¨', 'technology', 'à¤¤à¤•à¤¨à¥€à¤•', 'culture', 'à¤¸à¤‚à¤¸à¥à¤•à¥ƒà¤¤à¤¿'
            ]
        }
        
        # Mixed query indicators
        self.mixed_indicators = [
            'and', 'aur', 'à¤­à¥€', 'also', 'bhi', 'plus', 'à¤¸à¤¾à¤¥', 'together', 'à¤¸à¤¾à¤¥ à¤®à¥‡à¤‚',
            'both', 'à¤¦à¥‹à¤¨à¥‹à¤‚', 'along with', 'à¤•à¥‡ à¤¸à¤¾à¤¥', 'including', 'à¤¸à¤¹à¤¿à¤¤'
        ]
        
        # Language detection patterns
        self.hindi_patterns = [
            'à¤•à¥à¤¯à¤¾', 'à¤•à¥ˆà¤¸à¥‡', 'à¤•à¤¬', 'à¤•à¤¹à¤¾à¤‚', 'à¤•à¥Œà¤¨', 'à¤•à¥à¤¯à¥‹à¤‚', 'à¤®à¥‡à¤‚', 'à¤ªà¤°', 'à¤¸à¥‡', 'à¤•à¥‹',
            'à¤¹à¥ˆ', 'à¤¹à¥ˆà¤‚', 'à¤¥à¤¾', 'à¤¥à¥‡', 'à¤¥à¥€', 'à¤¹à¥‹à¤—à¤¾', 'à¤¹à¥‹à¤—à¥€', 'à¤¹à¥‹à¤‚à¤—à¥‡', 'à¤•à¤°', 'à¤•à¤°à¤¨à¤¾'
        ]
        
        self.english_patterns = [
            'what', 'how', 'when', 'where', 'who', 'why', 'is', 'are', 'was', 'were',
            'will', 'would', 'can', 'could', 'should', 'may', 'might', 'do', 'does', 'did'
        ]
    
    def classify_query(self, query: str) -> Dict[str, Any]:
        """Enhanced query classification with improved accuracy"""
        
        query_lower = query.lower().strip()
        
        # Detect language
        language = self._detect_language(query_lower)
        
        # Check for mixed queries first
        is_mixed = self._is_mixed_query(query_lower)
        
        # Classify query type with enhanced priority for farming queries
        if is_mixed:
            query_type = 'mixed'
            confidence = self._calculate_mixed_confidence(query_lower)
        else:
            farming_score = self._calculate_farming_score(query_lower)
            general_score = self._calculate_general_score(query_lower)
            
            # Check for specific crop recommendation patterns
            crop_recommendation_patterns = ['fasal', 'à¤«à¤¸à¤²', 'lagayein', 'à¤²à¤—à¤¾à¤à¤‚', 'suggest', 'à¤¸à¥à¤à¤¾à¤µ', 'recommend', 'à¤•à¥Œà¤¨ à¤¸à¥€', 'kya']
            has_crop_keywords = any(pattern in query_lower for pattern in crop_recommendation_patterns)
            
            # Prioritize farming if crop-related keywords are found
            if has_crop_keywords and farming_score > 0:
                query_type = 'farming'
                confidence = max(farming_score, 0.8)  # Boost confidence for crop queries
            elif farming_score > general_score:
                query_type = 'farming'
                confidence = farming_score
            else:
                query_type = 'general'
                confidence = general_score
        
        # Extract entities
        entities = self._extract_entities(query_lower, query_type)
        
        # Determine subcategory
        subcategory = self._determine_subcategory(query_lower, query_type)
        
        return {
            'query_type': query_type,
            'subcategory': subcategory,
            'language': language,
            'confidence': confidence,
            'entities': entities,
            'is_mixed': is_mixed,
            'classification_details': {
                'farming_score': self._calculate_farming_score(query_lower),
                'general_score': self._calculate_general_score(query_lower),
                'mixed_score': self._calculate_mixed_confidence(query_lower) if is_mixed else 0
            }
        }
    
    def _detect_language(self, query: str) -> str:
        """Enhanced language detection"""
        hindi_count = sum(1 for pattern in self.hindi_patterns if pattern in query)
        english_count = sum(1 for pattern in self.english_patterns if pattern in query)
        
        # Check for Devanagari script
        devanagari_count = len(re.findall(r'[\u0900-\u097F]', query))
        
        if devanagari_count > 0:
            return 'hi'
        elif hindi_count > english_count:
            return 'hinglish'
        else:
            return 'en'
    
    def _is_mixed_query(self, query: str) -> bool:
        """Detect mixed queries (farming + general)"""
        mixed_indicators_found = any(indicator in query for indicator in self.mixed_indicators)
        
        if not mixed_indicators_found:
            return False
        
        # Check if query contains both farming and general elements
        farming_elements = sum(1 for category in self.farming_patterns.values() 
                             for keyword in category if keyword in query)
        general_elements = sum(1 for category in self.general_patterns.values() 
                             for keyword in category if keyword in query)
        
        return farming_elements > 0 and general_elements > 0
    
    def _calculate_farming_score(self, query: str) -> float:
        """Calculate farming relevance score"""
        total_score = 0
        total_weight = 0
        
        for category, keywords in self.farming_patterns.items():
            category_score = sum(1 for keyword in keywords if keyword in query)
            weight = len(keywords)
            
            if category_score > 0:
                total_score += (category_score / weight) * 100
                total_weight += 100
        
        return min(total_score / total_weight, 1.0) if total_weight > 0 else 0.0
    
    def _calculate_general_score(self, query: str) -> float:
        """Calculate general query relevance score"""
        total_score = 0
        total_weight = 0
        
        for category, keywords in self.general_patterns.items():
            category_score = sum(1 for keyword in keywords if keyword in query)
            weight = len(keywords)
            
            if category_score > 0:
                total_score += (category_score / weight) * 100
                total_weight += 100
        
        return min(total_score / total_weight, 1.0) if total_weight > 0 else 0.0
    
    def _calculate_mixed_confidence(self, query: str) -> float:
        """Calculate confidence for mixed queries"""
        farming_score = self._calculate_farming_score(query)
        general_score = self._calculate_general_score(query)
        
        # Mixed queries should have both elements
        if farming_score > 0.3 and general_score > 0.3:
            return (farming_score + general_score) / 2
        else:
            return max(farming_score, general_score)
    
    def _extract_entities(self, query: str, query_type: str) -> Dict[str, Any]:
        """Extract entities from query"""
        entities = {
            'crops': [],
            'locations': [],
            'numbers': [],
            'keywords': []
        }
        
        # Extract crop names
        for crop in self.farming_patterns['crops']:
            if crop in query:
                entities['crops'].append(crop)
        
        # Extract locations (simple pattern matching)
        location_patterns = [
            r'\b(delhi|mumbai|bangalore|chennai|kolkata|hyderabad|pune|ahmedabad|jaipur|lucknow|kanpur|nagpur|indore|thane|bhopal|visakhapatnam|pimpri|patna|vadodara|ghaziabad|ludhiana|agra|nashik|faridabad|meerut|rajkot|kalyan|vasai|varanasi|srinagar|aurangabad|noida|solapur|howrah|coimbatore|raipur|jabalpur|gwalior|madurai|guwahati|chandigarh|tiruchirappalli|mysore|bhubaneswar|kochi|bhavnagar|salem|warangal|guntur|bhiwandi|amravati|nanded|kolhapur|sangli|malegaon|ulhasnagar|jalgaon|akola|latur|ahmadnagar|dhule|ichalkaranji|parbhani|jalna|bhusawal|panvel|satara|beed|yavatmal|kamptee|gondia|bhandara|udaipur|tirupur|mangalore|erode|belgaum|tumkur|davangere|bellary|bijapur|gulbarga|hubli|shimoga|udupi|hassan|mandya|chitradurga|kolar|chikmagalur|hampi|badami|pattadakal|aihole|halebidu|shravanabelagola|srirangapatna|melkote|talakad|somanathapura|belur|chennakeshava|hoysaleswara|ishvara|lakshmi|narayana|virupaksha|hampi|vijayanagara|bidar|raichur|kurnool|anantapur|kadapa|chittoor|nellore|prakasam|guntur|krishna|west godavari|east godavari|visakhapatnam|vizianagaram|srikakulam|adilabad|karimnagar|warangal|khammam|nalgonda|mahbubnagar|rangareddy|medak|nizamabad|hyderabad|secunderabad)\b',
            r'\b(uttar pradesh|maharashtra|karnataka|tamil nadu|west bengal|gujarat|rajasthan|madhya pradesh|andhra pradesh|telangana|bihar|odisha|kerala|assam|punjab|haryana|chhattisgarh|jharkhand|uttarakhand|himachal pradesh|tripura|meghalaya|manipur|nagaland|goa|arunachal pradesh|mizoram|sikkim|delhi|chandigarh|puducherry|andaman|nicobar|lakshadweep|daman|diu|dadra|nagar haveli)\b'
        ]
        
        for pattern in location_patterns:
            matches = re.findall(pattern, query, re.IGNORECASE)
            entities['locations'].extend(matches)
        
        # Extract numbers
        numbers = re.findall(r'\d+', query)
        entities['numbers'] = numbers
        
        # Extract key keywords
        all_keywords = []
        for category in self.farming_patterns.values():
            all_keywords.extend(category)
        for category in self.general_patterns.values():
            all_keywords.extend(category)
        
        entities['keywords'] = [kw for kw in all_keywords if kw in query]
        
        return entities
    
    def _determine_subcategory(self, query: str, query_type: str) -> str:
        """Determine specific subcategory"""
        if query_type == 'farming':
            for category, keywords in self.farming_patterns.items():
                if any(keyword in query for keyword in keywords):
                    return category
            return 'general_farming'
        
        elif query_type == 'general':
            for category, keywords in self.general_patterns.items():
                if any(keyword in query for keyword in keywords):
                    return category
            return 'general_knowledge'
        
        else:  # mixed
            return 'mixed_query'
    
    def get_classification_explanation(self, classification: Dict[str, Any]) -> str:
        """Get human-readable explanation of classification"""
        query_type = classification['query_type']
        confidence = classification['confidence']
        subcategory = classification['subcategory']
        
        if query_type == 'farming':
            return f"ðŸŒ¾ Farming Query ({subcategory}) - Confidence: {confidence:.2f}"
        elif query_type == 'general':
            return f"ðŸŒ General Query ({subcategory}) - Confidence: {confidence:.2f}"
        else:
            return f"ðŸ”„ Mixed Query ({subcategory}) - Confidence: {confidence:.2f}"

    def classify_intent(self, query: str) -> Dict[str, Any]:
        """Classify query intent - method expected by tests"""
        return self.classify_query(query)
    
    def extract_entities(self, query: str) -> List[Dict[str, Any]]:
        """Extract entities from query - method expected by tests"""
        try:
            entities = []
            query_lower = query.lower()
            
            # Extract crop names
            for crop_name, crop_info in self._get_crop_database().items():
                if crop_name in query_lower or crop_info.get('name_hindi', '') in query:
                    entities.append({
                        'type': 'crop',
                        'value': crop_name,
                        'confidence': 0.9
                    })
            
            # Extract locations
            for location in self._get_location_keywords():
                if location in query_lower:
                    entities.append({
                        'type': 'location',
                        'value': location,
                        'confidence': 0.8
                    })
            
            # Extract numbers (prices, quantities)
            numbers = re.findall(r'\d+(?:\.\d+)?', query)
            for number in numbers:
                entities.append({
                    'type': 'number',
                    'value': number,
                    'confidence': 0.7
                })
            
            return entities
        except Exception as e:
            logger.error(f"Error extracting entities: {e}")
            return []
    
    def _get_crop_database(self) -> Dict[str, Any]:
        """Get crop database for entity extraction"""
        return {
            'wheat': {'name_hindi': 'à¤—à¥‡à¤¹à¥‚à¤‚'},
            'rice': {'name_hindi': 'à¤§à¤¾à¤¨'},
            'maize': {'name_hindi': 'à¤®à¤•à¥à¤•à¤¾'},
            'cotton': {'name_hindi': 'à¤•à¤ªà¤¾à¤¸'},
            'potato': {'name_hindi': 'à¤†à¤²à¥‚'},
            'tomato': {'name_hindi': 'à¤Ÿà¤®à¤¾à¤Ÿà¤°'},
            'onion': {'name_hindi': 'à¤ªà¥à¤¯à¤¾à¤œ'},
            'sugarcane': {'name_hindi': 'à¤—à¤¨à¥à¤¨à¤¾'}
        }
    
    def _get_location_keywords(self) -> List[str]:
        """Get location keywords for entity extraction"""
        return [
            'delhi', 'mumbai', 'bangalore', 'kolkata', 'chennai', 'hyderabad',
            'pune', 'ahmedabad', 'jaipur', 'lucknow', 'punjab', 'haryana',
            'uttar pradesh', 'bihar', 'west bengal', 'tamil nadu', 'karnataka',
            'maharashtra', 'gujarat', 'rajasthan'
        ]

# Create global instance
enhanced_classifier = EnhancedQueryClassifier()
